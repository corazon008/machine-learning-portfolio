{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The dataset used in this notebook can be found at:\n",
    "https://www.kaggle.com/datasets/samithsachidanandan/human-face-emotions"
   ],
   "id": "79bfd74a6b808a2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import EarlyStopping\n",
    "\n",
    "import seaborn as sns\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "from utils.mlflow import is_mlflow_server_running, set_mlflow_tracking_uri"
   ],
   "id": "77eb62eec3c0e434",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "IMG_SIZE = 64\n",
    "DATASET_PATH = Path(\"../data/Emotions/\")\n",
    "\n",
    "FIGURES_DIR = Path(\"figures/emotions/\")\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not is_mlflow_server_running():\n",
    "    raise RuntimeError(\"MLflow server is not running. Please start the MLflow server before running this notebook.\")\n",
    "\n",
    "set_mlflow_tracking_uri()\n",
    "mlflow.set_experiment(\"Emotions_Classification_gray\")"
   ],
   "id": "2e4afa16600711bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from computer_vision.src.transforms import get_transform\n",
    "\n",
    "transform = get_transform(IMG_SIZE, [0.5117, 0.5098, 0.5089], [0.2070, 0.2062, 0.2060])\n",
    "\n",
    "# the above mean and std were computed from the training set with the following function:\n",
    "\n",
    "\n",
    "ds = ImageFolder(root=DATASET_PATH,\n",
    "                 transform=transform)"
   ],
   "id": "41becd686dc308f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TEST_SIZE = 0.2\n",
    "SEED = 42\n",
    "\n",
    "# generate indices: instead of the actual data we pass in integers instead\n",
    "train_indices, test_indices, _, _ = train_test_split(\n",
    "    range(len(ds)),\n",
    "    ds.targets,\n",
    "    stratify=ds.targets,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# generate subset based on indices\n",
    "train_dataset = Subset(ds, train_indices)\n",
    "test_dataset = Subset(ds, test_indices)\n"
   ],
   "id": "370e93e1a1413cd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(test_dataset), len(train_dataset)",
   "id": "d2472e6ad4bfa3e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualize some images",
   "id": "6f8867e81835b17b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_example, y_example = zip(*islice(iter(train_dataset), 7))",
   "id": "bfbf2d700f777bca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from computer_vision.src.figures import plot_example\n",
    "\n",
    "plot_example(torch.stack(X_example), y_example, ds.classes, n=7, mean=transform.transforms[2].mean, std=transform.transforms[2].std);"
   ],
   "id": "8221bb3e7bde93fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Are images RGB or grayscale?\n",
    "print(f\"Image shape: {X_example[0].shape}\")  # should print (3, IMG_SIZE, IMG_SIZE) for RGB images"
   ],
   "id": "f38186089583bee4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Distribution of classes in the training set",
   "id": "c2de1135d8e5e2de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from computer_vision.src.figures import plot_label_distribution\n",
    "\n",
    "figures_name = FIGURES_DIR / \"class_distribution.png\"\n",
    "\n",
    "plot_label_distribution(ds, figures_name)"
   ],
   "id": "928a25f754b82923",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training a baseline model",
   "id": "d7163464c81031b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_train = np.array([y for x, y in iter(train_dataset)])\n",
    "y_test = np.array([y for x, y in iter(test_dataset)])"
   ],
   "id": "6d7457245994c153",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
   "id": "b8dd76cd860901c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from computer_vision.src.baseline import BaselineModel\n",
    "torch.manual_seed(0)\n",
    "\n",
    "params = {\n",
    "    'max_epochs': 10,\n",
    "    'lr': 0.01,\n",
    "    'batch_size': 64,\n",
    "}\n",
    "\n",
    "baseline = NeuralNetClassifier(\n",
    "    BaselineModel,\n",
    "    iterator_train__num_workers=2,\n",
    "    iterator_valid__num_workers=2,\n",
    "    callbacks=[EarlyStopping(patience=3)],\n",
    "    device=device,\n",
    "    module__input_dim=IMG_SIZE*IMG_SIZE*3,\n",
    "    **params\n",
    ")"
   ],
   "id": "471086e67b26e3a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Wrap baseline training with MLflow tracking (params, per-epoch metrics, artifacts, model)\n",
    "with mlflow.start_run(run_name=\"baseline_run\"):\n",
    "    # Log some useful params\n",
    "    mlflow.set_tag(\"model_type\", \"BaselineModel\")\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Fit\n",
    "    baseline.fit(train_dataset, y=y_train)\n",
    "\n",
    "    # Log per-epoch metrics from skorch history\n",
    "    for epoch, row in enumerate(baseline.history):\n",
    "        if 'train_loss' in row:\n",
    "            mlflow.log_metric('train_loss', float(row['train_loss']), step=epoch)\n",
    "        if 'valid_loss' in row:\n",
    "            mlflow.log_metric('val_loss', float(row['valid_loss']), step=epoch)\n",
    "        if 'train_accuracy' in row:\n",
    "            mlflow.log_metric('train_acc', float(row['train_accuracy']), step=epoch)\n",
    "        if 'valid_accuracy' in row:\n",
    "            mlflow.log_metric('val_acc', float(row['valid_accuracy']), step=epoch)\n",
    "\n",
    "    # Save and log loss plot\n",
    "    try:\n",
    "        train_loss_history = baseline.history[:, 'train_loss']\n",
    "        val_loss_history = baseline.history[:, 'valid_loss']\n",
    "        plt.figure()\n",
    "        sns.lineplot(x=range(1, len(train_loss_history) + 1), y=train_loss_history, label='Train Loss')\n",
    "        sns.lineplot(x=range(1, len(val_loss_history) + 1), y=val_loss_history , label='Validation Loss')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Baseline: Training Loss over Epochs\")\n",
    "        baseline_fig = FIGURES_DIR / \"baseline_loss.png\"\n",
    "        plt.savefig(baseline_fig)\n",
    "        plt.show()\n",
    "        mlflow.log_artifact(str(baseline_fig))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Also log class distribution figure created earlier\n",
    "    try:\n",
    "        mlflow.log_artifact(str(figures_name))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Log trained model (try mlflow.pytorch; fallback to state_dict artifact)\n",
    "    try:\n",
    "        mlflow.pytorch.log_model(baseline.module_, artifact_path=\"baseline_model\")\n",
    "    except Exception:\n",
    "        torch.save(baseline.module_.state_dict(), \"baseline_model_state_dict.pth\")\n",
    "        mlflow.log_artifact(\"baseline_model_state_dict.pth\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    try:\n",
    "        acc = 100 * baseline.score(test_dataset, y_test)\n",
    "        print(\"Test set Accuracy: {:.2f}%\".format(acc))\n",
    "        mlflow.log_metric('test_accuracy', float(acc))\n",
    "    except Exception:\n",
    "        pass"
   ],
   "id": "3e71bae1c2486a27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Use BaseCNN with custom parameters",
   "id": "9fe503aae44d3c39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from computer_vision.src.BaseCNN import BaseCNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skorch.helper import SliceDataset\n",
    "\n",
    "params = {\n",
    "    'max_epochs': 10,\n",
    "    'lr': 0.001,\n",
    "    'optimizer': optim.Adam,\n",
    "    'callbacks': [EarlyStopping(patience=3)],\n",
    "\n",
    "    'module__img_size': IMG_SIZE,\n",
    "    'module__nb_conv_layers': 2,\n",
    "    'module__nb_layers': 2,\n",
    "    'module__net_width': 256,\n",
    "    'module__dropout_rates': [0.25, 0.5],\n",
    "}\n",
    "\n",
    "cnn = NeuralNetClassifier(\n",
    "    BaseCNN,\n",
    "    #max_epochs=10,\n",
    "    #lr=0.001,\n",
    "    #optimizer=optim.Adam,\n",
    "    device=device,\n",
    "    #callbacks=[EarlyStopping(patience=3)],\n",
    "\n",
    "    module__num_classes=5,\n",
    "    #module__nb_img_channels=1, # grayscale images\n",
    "\n",
    "    **params\n",
    ")"
   ],
   "id": "3a74de7c1b893ebe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Wrap BaseCNN training with MLflow tracking\n",
    "with mlflow.start_run(run_name=\"basecnn_run\"):\n",
    "    mlflow.set_tag(\"model_type\", \"BaseCNN\")\n",
    "    # log key params\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    cnn.fit(train_dataset, y_train)\n",
    "\n",
    "    # log history metrics\n",
    "    for epoch, row in enumerate(cnn.history):\n",
    "        if 'train_loss' in row:\n",
    "            mlflow.log_metric('train_loss', float(row['train_loss']), step=epoch)\n",
    "        if 'valid_loss' in row:\n",
    "            mlflow.log_metric('val_loss', float(row['valid_loss']), step=epoch)\n",
    "\n",
    "    # save and log plot\n",
    "    try:\n",
    "        train_loss_history = cnn.history[:, 'train_loss']\n",
    "        valid_loss_history = cnn.history[:, 'valid_loss']\n",
    "        plt.figure()\n",
    "        sns.lineplot(x=range(1, len(train_loss_history) + 1), y=train_loss_history, label='Train Loss')\n",
    "        sns.lineplot(x=range(1, len(valid_loss_history) + 1), y=valid_loss_history , label='Validation Loss')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"BaseCNN: Training Loss over Epochs\")\n",
    "        cnn_fig = FIGURES_DIR / \"cnn_loss.png\"\n",
    "        plt.savefig(cnn_fig)\n",
    "        plt.show()\n",
    "        mlflow.log_artifact(str(cnn_fig))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        mlflow.pytorch.log_model(cnn.module_, artifact_path=\"basecnn_model\")\n",
    "    except Exception:\n",
    "        torch.save(cnn.module_.state_dict(), \"basecnn_model_state_dict.pth\")\n",
    "        mlflow.log_artifact(\"basecnn_model_state_dict.pth\")\n",
    "\n",
    "    acc = 100 * cnn.score(test_dataset, y_test)\n",
    "    print(\"Test set Accuracy: {:.2f}%\".format(acc))\n",
    "    mlflow.log_metric('test_accuracy', float(acc))\n"
   ],
   "id": "8448f53d10079ed5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameter Tuning with Grid Search",
   "id": "98a30a400d2372b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from computer_vision.src.BaseCNN import BaseCNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skorch.helper import SliceDataset\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    BaseCNN,\n",
    "    max_epochs=10,\n",
    "    lr=0.01,\n",
    "    callbacks=[EarlyStopping(patience=3)],\n",
    "\n",
    "    module__num_classes=5,\n",
    "    module__img_size=IMG_SIZE,\n",
    "    #module__nb_img_channels=1, # grayscale images\n",
    "    device=device,\n",
    "\n",
    ")"
   ],
   "id": "c845eec4837edddc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "params = [\n",
    "    {\n",
    "        'optimizer': [optim.Adam],\n",
    "        'lr': [1e-3],\n",
    "        'module__nb_conv_layers': [2, 3],\n",
    "        'module__nb_layers': [2, 3],\n",
    "        'module__net_width': [128, 256],\n",
    "    },\n",
    "    {\n",
    "        'optimizer': [optim.SGD],\n",
    "        'lr': [0.05],\n",
    "        'module__nb_conv_layers': [2, 3],\n",
    "        'module__nb_layers': [2, 3],\n",
    "        'module__net_width': [128, 256],\n",
    "    }\n",
    "]"
   ],
   "id": "74e0fc7c59c4a6e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "grid = GridSearchCV(net, params, cv=2, scoring='accuracy', verbose=2, n_jobs=-1)",
   "id": "47e334c4c5763619",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_dataset_sliceable = SliceDataset(train_dataset)",
   "id": "99456dd2c1c80575",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Wrap GridSearch with MLflow tracking\n",
    "with mlflow.start_run(run_name=\"gridsearch_run\"):\n",
    "    mlflow.set_tag('procedure', 'GridSearchCV')\n",
    "    try:\n",
    "        mlflow.log_param('param_grid', str(params))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    grid.fit(train_dataset_sliceable, y_train)\n",
    "    mlflow.log_param('best_params', str(grid.best_params_))\n",
    "    mlflow.log_metric('best_cv_accuracy', float(grid.best_score_)*100)\n",
    "\n",
    "    # Optionally log the best estimator model\n",
    "    try:\n",
    "        best_model = grid.best_estimator_.module_\n",
    "        mlflow.pytorch.log_model(best_model, artifact_path='grid_best_model')\n",
    "    except Exception:\n",
    "        try:\n",
    "            torch.save(grid.best_estimator_.module_.state_dict(), 'grid_best_model_state_dict.pth')\n",
    "            mlflow.log_artifact('grid_best_model_state_dict.pth')\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    print(\"Best parameters found: \", grid.best_params_)\n",
    "    print(\"Best cross-validation accuracy: \", grid.best_score_)\n",
    "    print(\"Test set accuracy: \", grid.score(SliceDataset(test_dataset), y_test))\n",
    "\n",
    "    mlflow.log_metric('test_accuracy', float(grid.score(SliceDataset(test_dataset), y_test))*100)\n",
    "\n",
    "    for epoch, row in enumerate(grid.best_estimator_.history):\n",
    "        if 'train_loss' in row:\n",
    "            mlflow.log_metric('train_loss', float(row['train_loss']), step=epoch)\n",
    "        if 'valid_loss' in row:\n",
    "            mlflow.log_metric('val_loss', float(row['valid_loss']), step=epoch)\n"
   ],
   "id": "2ff03386d41edba6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2f8e62c647f5ac87",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
