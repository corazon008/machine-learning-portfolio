{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from utils.helper import find_project_root"
   ],
   "id": "d67bd4f870223938",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATASET_PATH = find_project_root() / Path(\"datasets/nlp/\")\n",
    "\n",
    "df = pd.read_csv(DATASET_PATH / \"IMDB Dataset.csv.zip\")"
   ],
   "id": "1d530095b0c03f50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Vectorize the text using TF-IDF\n",
    "TF-IDF (Term Frequency-Inverse Document Frequency) is a common technique to convert text into numerical features. It assigns a weight to each word based on its frequency in the document and its rarity across the corpus. This helps to highlight important words while downplaying common ones."
   ],
   "id": "d8823447d9223287"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from nlp.data.preprocessing import TextPreprocessor\n",
    "from nlp.features.tfidf import TfidfVectorizerWrapper\n",
    "from nlp.pipelines.tfidf_pipeline import TFIDFPipeline"
   ],
   "id": "7a452c64340d693b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[\"sentiment\"] = df[\"sentiment\"].map({\"positive\": 1, \"negative\": 0})",
   "id": "9624d98872afc46d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"review\"], df[\"sentiment\"], test_size=0.2, random_state=42\n",
    ")"
   ],
   "id": "17d69e3a5ecc90b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Train a Logistic Regression model\n",
    "Logistic Regression is a simple yet effective linear model for binary classification tasks. It estimates the probability that a given input belongs to a particular class (positive or negative in this case) based on the features extracted from the text. The model learns to assign weights to each feature (word) to make predictions. It is often used as a baseline in text classification tasks due to its simplicity and interpretability"
   ],
   "id": "14f094db4f25803d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from nlp.models.linear import LogisticRegressionModel\n",
    "\n",
    "pipeline = TFIDFPipeline(TextPreprocessor(), TfidfVectorizerWrapper(), LogisticRegressionModel(C=1.0))\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "top_pos, top_neg = pipeline.model.get_top_features(\n",
    "    pipeline.vectorizer.get_feature_names(),\n",
    "    k=10,\n",
    ")\n",
    "\n",
    "print(\"Top positive features:\")\n",
    "for w, c in top_pos:\n",
    "    print(w, c)\n",
    "\n",
    "print(\"\\nTop negative features:\")\n",
    "for w, c in top_neg:\n",
    "    print(w, c)\n"
   ],
   "id": "82311b8dfa18ed15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from nlp.evaluation.metrics import evaluate_model, compute_confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "metrics = pipeline.evaluate(X_test, y_test)\n",
    "print(metrics)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "sns.heatmap(compute_confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\", cmap=\"Blues\")"
   ],
   "id": "d8823fbd1c43b180",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compare Naive Bayes and Logistic Regression",
   "id": "2d4d9e4daadf4b9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from nlp.models.linear import LogisticRegressionModel\n",
    "from nlp.models.naive_bayes import  MultinomialNBModel\n",
    "\n",
    "# Logistic Regression\n",
    "lr_pipeline = TFIDFPipeline(TextPreprocessor(), TfidfVectorizerWrapper(), LogisticRegressionModel(C=1.0))\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "lr_metrics = lr_pipeline.evaluate(X_test, y_test)\n",
    "\n",
    "# Naive Bayes\n",
    "nb_pipeline = TFIDFPipeline(TextPreprocessor(), TfidfVectorizerWrapper(), MultinomialNBModel(alpha=1.0))\n",
    "nb_pipeline.fit(X_train, y_train)\n",
    "nb_metrics = nb_pipeline.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Logistic Regression:\", lr_metrics)\n",
    "print(\"Naive Bayes:\", nb_metrics)"
   ],
   "id": "b0ff9ff6dec1df3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results_df = pd.DataFrame([lr_metrics, nb_metrics],\n",
    "                          index=[\"LogisticRegression\", \"NaiveBayes\"])\n",
    "\n",
    "results_df"
   ],
   "id": "3f9d3cc33dd0478a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sns.heatmap(compute_confusion_matrix(y_test, lr_pipeline.predict(X_test)), annot=True, fmt=\"d\", cmap=\"Blues\")",
   "id": "6c2a702b362c4de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sns.heatmap(compute_confusion_matrix(y_test, nb_pipeline.predict(X_test)), annot=True, fmt=\"d\", cmap=\"Blues\")",
   "id": "f7fda7ff1cf815ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Analyze misclassified examples\n",
    "Analyzing misclassified examples can provide insights into the model's weaknesses and help identify patterns that lead to incorrect predictions. By examining these examples, we can understand whether the model struggles with certain types of reviews, specific words, or phrases that may be ambiguous. This analysis can guide further improvements to the model, such as adding more features, using different preprocessing techniques, or even collecting more data to address specific cases where the model fails."
   ],
   "id": "6d00ebb62c85211f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# false negative example\n",
    "misclassified_idxs = np.where(y_pred != y_test)\n",
    "\n",
    "exemple = X_test.iloc[misclassified_idxs[0][0]]\n",
    "print(f\"Predicted: {'Positive' if y_pred[misclassified_idxs[0][0]] == 1 else 'Negative'}, Actual: {'Positive' if y_test.iloc[misclassified_idxs[0][0]] == 1 else 'Negative'}\")\n",
    "print(exemple)"
   ],
   "id": "2b0733a84ea77564",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "y_pred = lr_pipeline.predict(X_test)\n",
    "\n",
    "mis_idx = np.where(y_pred != y_test)[0]\n",
    "\n",
    "len(mis_idx)\n"
   ],
   "id": "5b749b35ba95d662",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in mis_idx[:10]:\n",
    "    print(\"\\n\\n----------\")\n",
    "    print(\"TEXT:\", X_test.iloc[i])\n",
    "    print(\"TRUE:\", y_test.iloc[i])\n",
    "    print(\"PRED:\", y_pred[i])\n"
   ],
   "id": "2e715bb17ff5c934",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3bb6982950a2444a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
